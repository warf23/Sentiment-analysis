{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP du SVM en Sentiment Analysis\n",
    "### AGRAT MOHAMMED\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up completed ....\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "X = pd.read_csv('reviews.txt', names=['review'])\n",
    "y = pd.read_csv('labels.txt',names=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 1), (5000, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape , y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bromwell high is a cartoon comedy . it ran at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>story of a man who has unnatural feelings for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>homelessness  or houselessness as george carli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>airport    starts as a brand new luxury    pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brilliant over  acting by lesley ann warren . ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  bromwell high is a cartoon comedy . it ran at ...\n",
       "1  story of a man who has unnatural feelings for ...\n",
       "2  homelessness  or houselessness as george carli...\n",
       "3  airport    starts as a brand new luxury    pla...\n",
       "4  brilliant over  acting by lesley ann warren . ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label\n",
       "0  positive\n",
       "1  negative\n",
       "2  positive\n",
       "3  negative\n",
       "4  positive"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='label'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y['label'].value_counts().plot(kind='pie' ,  autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.label.map({'positive':1 , 'negative':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3- prepare the data for training :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text: str) -> str:\n",
    "    doc = nlp(text.lower())\n",
    "    tokens = [ word.lemma_ for word in doc if not (word.is_stop or word.is_punct)]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"processed_review\"] = X.review.apply(lambda text:preprocessing(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>processed_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bromwell high is a cartoon comedy . it ran at ...</td>\n",
       "      <td>bromwell high cartoon comedy run time program ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>story of a man who has unnatural feelings for ...</td>\n",
       "      <td>story man unnatural feeling pig start opening ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>homelessness  or houselessness as george carli...</td>\n",
       "      <td>homelessness   houselessness george carlin sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>airport    starts as a brand new luxury    pla...</td>\n",
       "      <td>airport     start brand new luxury     plane l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brilliant over  acting by lesley ann warren . ...</td>\n",
       "      <td>brilliant   act lesley ann warren well dramati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  bromwell high is a cartoon comedy . it ran at ...   \n",
       "1  story of a man who has unnatural feelings for ...   \n",
       "2  homelessness  or houselessness as george carli...   \n",
       "3  airport    starts as a brand new luxury    pla...   \n",
       "4  brilliant over  acting by lesley ann warren . ...   \n",
       "\n",
       "                                    processed_review  \n",
       "0  bromwell high cartoon comedy run time program ...  \n",
       "1  story man unnatural feeling pig start opening ...  \n",
       "2  homelessness   houselessness george carlin sta...  \n",
       "3  airport     start brand new luxury     plane l...  \n",
       "4  brilliant   act lesley ann warren well dramati...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.processed_review, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4000,), (4000,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X_train = cv.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 26016)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4- train the SVM model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[CV 1/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.863 total time=   6.8s\n",
      "[CV 2/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.850 total time=   5.7s\n",
      "[CV 3/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.850 total time=   5.9s\n",
      "[CV 4/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.864 total time=   6.1s\n",
      "[CV 5/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.854 total time=   5.7s\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.500 total time=  13.0s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.500 total time=  13.2s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.500 total time=  13.0s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.500 total time=  13.1s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.585 total time=  13.5s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.863 total time=   6.2s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.850 total time=   8.6s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.850 total time=  14.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.864 total time=  14.6s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.854 total time=  12.7s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.500 total time=  13.1s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.500 total time=  12.6s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.500 total time=  13.1s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.500 total time=  12.1s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.520 total time=  19.6s\n",
      "[CV 1/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.863 total time=   7.9s\n",
      "[CV 2/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.850 total time=   5.9s\n",
      "[CV 3/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.850 total time=   5.8s\n",
      "[CV 4/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.864 total time=   5.9s\n",
      "[CV 5/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.854 total time=   5.9s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.640 total time=  12.3s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.625 total time=  11.9s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.603 total time=  12.2s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.613 total time=  12.2s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.627 total time=  12.3s\n",
      "[CV 1/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.863 total time=   5.7s\n",
      "[CV 2/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.850 total time=   5.9s\n",
      "[CV 3/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.850 total time=   6.3s\n",
      "[CV 4/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.864 total time=   5.7s\n",
      "[CV 5/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.854 total time=   5.8s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.660 total time=  13.9s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.665 total time=  12.7s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.632 total time=  11.8s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.715 total time=  12.6s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.703 total time=  12.4s\n",
      "[CV 1/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.863 total time=   6.3s\n",
      "[CV 2/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.850 total time=   6.0s\n",
      "[CV 3/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.850 total time=   5.1s\n",
      "[CV 4/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.864 total time=   5.9s\n",
      "[CV 5/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.854 total time=   6.1s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.500 total time=  13.9s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.500 total time=  13.0s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.500 total time=  13.2s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.500 total time=  13.8s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.634 total time=  21.6s\n",
      "[CV 1/5] END .......C=1, gamma=1, kernel=linear;, score=0.859 total time=  12.9s\n",
      "[CV 2/5] END .......C=1, gamma=1, kernel=linear;, score=0.845 total time=   5.7s\n",
      "[CV 3/5] END .......C=1, gamma=1, kernel=linear;, score=0.851 total time=   5.9s\n",
      "[CV 4/5] END .......C=1, gamma=1, kernel=linear;, score=0.851 total time=   5.9s\n",
      "[CV 5/5] END .......C=1, gamma=1, kernel=linear;, score=0.855 total time=   5.7s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.500 total time=  13.1s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.500 total time=  14.9s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.500 total time=  14.6s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.502 total time=  14.8s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.500 total time=  14.7s\n",
      "[CV 1/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.859 total time=   6.4s\n",
      "[CV 2/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.845 total time=   6.5s\n",
      "[CV 3/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.851 total time=   6.4s\n",
      "[CV 4/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.851 total time=   6.6s\n",
      "[CV 5/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.855 total time=   6.3s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.547 total time=  15.4s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.544 total time=  13.2s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.544 total time=  13.5s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.535 total time=  13.7s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.539 total time=  13.6s\n",
      "[CV 1/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.859 total time=   6.6s\n",
      "[CV 2/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.845 total time=   6.5s\n",
      "[CV 3/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.851 total time=   6.6s\n",
      "[CV 4/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.851 total time=   6.7s\n",
      "[CV 5/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.855 total time=   5.9s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.831 total time=  13.2s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.814 total time=  13.6s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.836 total time=  12.7s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.811 total time=  13.2s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.789 total time=  13.7s\n",
      "[CV 1/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.859 total time=   6.6s\n",
      "[CV 2/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.845 total time=   6.3s\n",
      "[CV 3/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.851 total time=   6.3s\n",
      "[CV 4/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.851 total time=   6.0s\n",
      "[CV 5/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.855 total time=   5.4s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.836 total time=  10.4s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.843 total time=  10.6s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.835 total time=  10.0s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.836 total time=  10.6s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.838 total time=  10.5s\n",
      "[CV 1/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.859 total time=   5.7s\n",
      "[CV 2/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.845 total time=   5.4s\n",
      "[CV 3/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.851 total time=   5.8s\n",
      "[CV 4/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.851 total time=   6.3s\n",
      "[CV 5/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.855 total time=   6.2s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.655 total time=  14.0s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.664 total time=  12.6s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.637 total time=  12.7s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.719 total time=  11.8s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.705 total time=  12.9s\n",
      "[CV 1/5] END ......C=10, gamma=1, kernel=linear;, score=0.856 total time=   6.4s\n",
      "[CV 2/5] END ......C=10, gamma=1, kernel=linear;, score=0.846 total time=   6.0s\n",
      "[CV 3/5] END ......C=10, gamma=1, kernel=linear;, score=0.851 total time=   6.3s\n",
      "[CV 4/5] END ......C=10, gamma=1, kernel=linear;, score=0.854 total time=   6.1s\n",
      "[CV 5/5] END ......C=10, gamma=1, kernel=linear;, score=0.851 total time=   6.5s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.500 total time=  14.5s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.501 total time=  14.3s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.500 total time=  14.9s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.502 total time=  14.5s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.500 total time=  14.1s\n",
      "[CV 1/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.856 total time=   6.3s\n",
      "[CV 2/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.846 total time=   6.1s\n",
      "[CV 3/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.851 total time=   5.9s\n",
      "[CV 4/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.854 total time=   6.4s\n",
      "[CV 5/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.851 total time=   6.4s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.569 total time=  12.1s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.579 total time=  12.9s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.555 total time=  27.1s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.557 total time=  31.4s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.560 total time=  31.8s\n",
      "[CV 1/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.856 total time=  13.9s\n",
      "[CV 2/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.846 total time=  12.7s\n",
      "[CV 3/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.851 total time=   5.8s\n",
      "[CV 4/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.854 total time=   5.9s\n",
      "[CV 5/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.851 total time=   5.9s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.840 total time=  13.8s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.823 total time=  13.9s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.836 total time=  13.7s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.831 total time=  12.3s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.804 total time=  13.7s\n",
      "[CV 1/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.856 total time=   6.4s\n",
      "[CV 2/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.846 total time=   6.1s\n",
      "[CV 3/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.851 total time=   5.6s\n",
      "[CV 4/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.854 total time=   6.6s\n",
      "[CV 5/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.851 total time=   6.1s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.891 total time=   7.8s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.865 total time=   7.3s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.876 total time=   7.4s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.873 total time=   7.6s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.874 total time=   8.2s\n",
      "[CV 1/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.856 total time=   6.3s\n",
      "[CV 2/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.846 total time=   6.5s\n",
      "[CV 3/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.851 total time=   6.0s\n",
      "[CV 4/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.854 total time=   5.9s\n",
      "[CV 5/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.851 total time=   6.7s\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.846 total time=  10.3s\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.851 total time=  10.2s\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.846 total time=   9.6s\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.853 total time=  10.2s\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.849 total time=  10.3s\n",
      "[CV 1/5] END .....C=100, gamma=1, kernel=linear;, score=0.856 total time=   6.7s\n",
      "[CV 2/5] END .....C=100, gamma=1, kernel=linear;, score=0.846 total time=   6.3s\n",
      "[CV 3/5] END .....C=100, gamma=1, kernel=linear;, score=0.851 total time=   6.3s\n",
      "[CV 4/5] END .....C=100, gamma=1, kernel=linear;, score=0.854 total time=   6.1s\n",
      "[CV 5/5] END .....C=100, gamma=1, kernel=linear;, score=0.851 total time=   6.1s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.500 total time=  14.5s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.501 total time=  13.7s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.500 total time=  14.3s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.502 total time=  14.3s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.500 total time=  14.5s\n",
      "[CV 1/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.856 total time=   6.7s\n",
      "[CV 2/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.846 total time=   6.2s\n",
      "[CV 3/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.851 total time=   5.7s\n",
      "[CV 4/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.854 total time=   6.6s\n",
      "[CV 5/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.851 total time=   5.7s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.569 total time=  14.6s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.579 total time=  12.6s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.555 total time=  13.5s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.557 total time=  13.8s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.560 total time=  14.3s\n",
      "[CV 1/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.856 total time=   6.9s\n",
      "[CV 2/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.846 total time=   6.3s\n",
      "[CV 3/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.851 total time=   6.1s\n",
      "[CV 4/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.854 total time=   6.2s\n",
      "[CV 5/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.851 total time=   6.3s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.836 total time=  13.6s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.823 total time=  13.2s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.838 total time=  14.0s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.836 total time=  14.2s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.799 total time=  13.8s\n",
      "[CV 1/5] END .C=100, gamma=0.001, kernel=linear;, score=0.856 total time=   5.7s\n",
      "[CV 2/5] END .C=100, gamma=0.001, kernel=linear;, score=0.846 total time=   6.0s\n",
      "[CV 3/5] END .C=100, gamma=0.001, kernel=linear;, score=0.851 total time=   6.1s\n",
      "[CV 4/5] END .C=100, gamma=0.001, kernel=linear;, score=0.854 total time=   6.3s\n",
      "[CV 5/5] END .C=100, gamma=0.001, kernel=linear;, score=0.851 total time=   6.3s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.869 total time=   9.8s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.856 total time=   9.7s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.856 total time=   9.5s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.870 total time=  10.3s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.864 total time=   9.5s\n",
      "[CV 1/5] END C=100, gamma=0.0001, kernel=linear;, score=0.856 total time=   5.7s\n",
      "[CV 2/5] END C=100, gamma=0.0001, kernel=linear;, score=0.846 total time=   5.4s\n",
      "[CV 3/5] END C=100, gamma=0.0001, kernel=linear;, score=0.851 total time=   5.8s\n",
      "[CV 4/5] END C=100, gamma=0.0001, kernel=linear;, score=0.854 total time=   5.8s\n",
      "[CV 5/5] END C=100, gamma=0.0001, kernel=linear;, score=0.851 total time=   6.0s\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.894 total time=   7.2s\n",
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.861 total time=   6.9s\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.870 total time=   6.2s\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.877 total time=   7.1s\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.877 total time=   6.6s\n",
      "[CV 1/5] END ....C=1000, gamma=1, kernel=linear;, score=0.856 total time=   6.6s\n",
      "[CV 2/5] END ....C=1000, gamma=1, kernel=linear;, score=0.846 total time=   6.4s\n",
      "[CV 3/5] END ....C=1000, gamma=1, kernel=linear;, score=0.851 total time=   5.8s\n",
      "[CV 4/5] END ....C=1000, gamma=1, kernel=linear;, score=0.854 total time=   6.5s\n",
      "[CV 5/5] END ....C=1000, gamma=1, kernel=linear;, score=0.851 total time=   6.3s\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.500 total time=  14.1s\n",
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.501 total time=  14.7s\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.500 total time=  14.3s\n",
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.502 total time=  14.1s\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.500 total time=  14.0s\n",
      "[CV 1/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.856 total time=   6.7s\n",
      "[CV 2/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.846 total time=   6.3s\n",
      "[CV 3/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.851 total time=   6.5s\n",
      "[CV 4/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.854 total time=   6.3s\n",
      "[CV 5/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.851 total time=   6.0s\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.569 total time=  14.2s\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.579 total time=  14.9s\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.555 total time=  14.0s\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.557 total time=  13.4s\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.560 total time=  13.9s\n",
      "[CV 1/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.856 total time=   6.7s\n",
      "[CV 2/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.846 total time=   6.2s\n",
      "[CV 3/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.851 total time=   6.7s\n",
      "[CV 4/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.854 total time=   6.7s\n",
      "[CV 5/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.851 total time=   6.4s\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.836 total time=  13.6s\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.823 total time=  13.3s\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.838 total time=  14.0s\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.836 total time=  24.1s\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.799 total time=  27.1s\n",
      "[CV 1/5] END C=1000, gamma=0.001, kernel=linear;, score=0.856 total time=   5.6s\n",
      "[CV 2/5] END C=1000, gamma=0.001, kernel=linear;, score=0.846 total time=   4.5s\n",
      "[CV 3/5] END C=1000, gamma=0.001, kernel=linear;, score=0.851 total time=   5.1s\n",
      "[CV 4/5] END C=1000, gamma=0.001, kernel=linear;, score=0.854 total time=   6.7s\n",
      "[CV 5/5] END C=1000, gamma=0.001, kernel=linear;, score=0.851 total time=   6.4s\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.860 total time=   9.9s\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.853 total time=   9.6s\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.866 total time=   9.1s\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.869 total time=   9.6s\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.861 total time=   9.4s\n",
      "[CV 1/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.856 total time=   7.2s\n",
      "[CV 2/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.846 total time=   6.5s\n",
      "[CV 3/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.851 total time=   6.5s\n",
      "[CV 4/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.854 total time=   6.3s\n",
      "[CV 5/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.851 total time=   6.4s\n",
      "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.861 total time=   7.0s\n",
      "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.855 total time=   7.1s\n",
      "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.850 total time=   6.2s\n",
      "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.863 total time=   7.0s\n",
      "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.854 total time=   6.8s\n",
      "{'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "SVC(C=100, gamma=0.0001)\n"
     ]
    }
   ],
   "source": [
    "# Parameters to test for each SVM type\n",
    "parameters = {\n",
    "    'C': [0.1, 1, 10, 100, 1000],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "# SVM model\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "# Find the best hyperparameters for each SVM type\n",
    "grid_svm = GridSearchCV(svm_model, parameters, refit = True, verbose = 3)\n",
    "grid_svm.fit(X_train, y_train)\n",
    "\n",
    "# print best parameter after tuning\n",
    "print(grid_svm.best_params_)\n",
    "\n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid_svm.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5- regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\programing\\ML\\.env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_model = LogisticRegression()\n",
    "regression_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88       501\n",
      "           1       0.86      0.91      0.88       499\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.88      0.88      0.88      1000\n",
      "weighted avg       0.88      0.88      0.88      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predicted = regression_model.predict(X_test)\n",
    "\n",
    "# print classification report\n",
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6- using naive byes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_byes_model = MultinomialNB()\n",
    "naive_byes_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89       501\n",
      "           1       0.90      0.89      0.89       499\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.89      0.89      0.89      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predicted = naive_byes_model.predict(X_test)\n",
    "\n",
    "# print classification report\n",
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7- using KNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[CV 1/5] END .....................n_neighbors=1;, score=0.594 total time=   0.1s\n",
      "[CV 2/5] END .....................n_neighbors=1;, score=0.559 total time=   0.1s\n",
      "[CV 3/5] END .....................n_neighbors=1;, score=0.615 total time=   0.1s\n",
      "[CV 4/5] END .....................n_neighbors=1;, score=0.604 total time=   0.2s\n",
      "[CV 5/5] END .....................n_neighbors=1;, score=0.578 total time=   0.1s\n",
      "[CV 1/5] END .....................n_neighbors=3;, score=0.601 total time=   0.1s\n",
      "[CV 2/5] END .....................n_neighbors=3;, score=0.623 total time=   0.1s\n",
      "[CV 3/5] END .....................n_neighbors=3;, score=0.586 total time=   0.2s\n",
      "[CV 4/5] END .....................n_neighbors=3;, score=0.615 total time=   0.1s\n",
      "[CV 5/5] END .....................n_neighbors=3;, score=0.620 total time=   0.1s\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.614 total time=   0.1s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.654 total time=   0.2s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.603 total time=   0.2s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.624 total time=   0.1s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.619 total time=   0.1s\n",
      "[CV 1/5] END .....................n_neighbors=7;, score=0.637 total time=   0.1s\n",
      "[CV 2/5] END .....................n_neighbors=7;, score=0.670 total time=   0.1s\n",
      "[CV 3/5] END .....................n_neighbors=7;, score=0.629 total time=   0.2s\n",
      "[CV 4/5] END .....................n_neighbors=7;, score=0.654 total time=   0.1s\n",
      "[CV 5/5] END .....................n_neighbors=7;, score=0.635 total time=   0.1s\n",
      "[CV 1/5] END .....................n_neighbors=9;, score=0.656 total time=   0.1s\n",
      "[CV 2/5] END .....................n_neighbors=9;, score=0.665 total time=   0.1s\n",
      "[CV 3/5] END .....................n_neighbors=9;, score=0.645 total time=   0.1s\n",
      "[CV 4/5] END .....................n_neighbors=9;, score=0.659 total time=   0.1s\n",
      "[CV 5/5] END .....................n_neighbors=9;, score=0.645 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=11;, score=0.656 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=11;, score=0.649 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=11;, score=0.650 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=11;, score=0.665 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=11;, score=0.674 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=13;, score=0.652 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=13;, score=0.657 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=13;, score=0.650 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=13;, score=0.662 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=13;, score=0.689 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.665 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.650 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.647 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.656 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.676 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=17;, score=0.659 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=17;, score=0.649 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=17;, score=0.654 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=17;, score=0.667 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=17;, score=0.677 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=19;, score=0.656 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=19;, score=0.654 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=19;, score=0.640 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=19;, score=0.649 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=19;, score=0.681 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=21;, score=0.656 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=21;, score=0.651 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=21;, score=0.636 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=21;, score=0.657 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=21;, score=0.666 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=23;, score=0.657 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=23;, score=0.670 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=23;, score=0.640 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=23;, score=0.654 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=23;, score=0.664 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=25;, score=0.662 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=25;, score=0.660 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=25;, score=0.623 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=25;, score=0.661 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=25;, score=0.666 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=27;, score=0.655 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=27;, score=0.664 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=27;, score=0.619 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=27;, score=0.661 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=27;, score=0.670 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=29;, score=0.659 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=29;, score=0.665 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=29;, score=0.618 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=29;, score=0.657 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=29;, score=0.681 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=31;, score=0.650 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=31;, score=0.660 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=31;, score=0.620 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=31;, score=0.649 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=31;, score=0.669 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=33;, score=0.657 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=33;, score=0.666 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=33;, score=0.629 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=33;, score=0.656 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=33;, score=0.665 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=35;, score=0.651 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=35;, score=0.662 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=35;, score=0.632 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=35;, score=0.666 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=35;, score=0.655 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=37;, score=0.647 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=37;, score=0.656 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=37;, score=0.631 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=37;, score=0.662 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=37;, score=0.661 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=39;, score=0.637 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=39;, score=0.662 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=39;, score=0.634 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=39;, score=0.659 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=39;, score=0.657 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=41;, score=0.645 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=41;, score=0.656 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=41;, score=0.632 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=41;, score=0.656 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=41;, score=0.650 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=43;, score=0.640 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=43;, score=0.665 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=43;, score=0.637 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=43;, score=0.662 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=43;, score=0.656 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=45;, score=0.644 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=45;, score=0.661 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=45;, score=0.632 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=45;, score=0.666 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=45;, score=0.665 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=47;, score=0.647 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=47;, score=0.669 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=47;, score=0.634 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=47;, score=0.656 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=47;, score=0.657 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=49;, score=0.641 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=49;, score=0.670 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=49;, score=0.632 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=49;, score=0.649 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=49;, score=0.661 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=51;, score=0.636 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=51;, score=0.667 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=51;, score=0.640 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=51;, score=0.655 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=51;, score=0.665 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=53;, score=0.640 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=53;, score=0.665 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=53;, score=0.646 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=53;, score=0.664 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=53;, score=0.669 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=55;, score=0.629 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=55;, score=0.652 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=55;, score=0.636 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=55;, score=0.659 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=55;, score=0.666 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=57;, score=0.631 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=57;, score=0.649 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=57;, score=0.630 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=57;, score=0.652 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=57;, score=0.669 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=59;, score=0.629 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=59;, score=0.646 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=59;, score=0.631 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=59;, score=0.649 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=59;, score=0.662 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=61;, score=0.627 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=61;, score=0.649 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=61;, score=0.627 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=61;, score=0.656 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=61;, score=0.661 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=63;, score=0.635 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=63;, score=0.649 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=63;, score=0.626 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=63;, score=0.649 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=63;, score=0.657 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=65;, score=0.626 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=65;, score=0.652 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=65;, score=0.625 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=65;, score=0.659 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=65;, score=0.664 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=67;, score=0.634 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=67;, score=0.646 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=67;, score=0.621 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=67;, score=0.654 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=67;, score=0.647 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=69;, score=0.629 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=69;, score=0.646 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=69;, score=0.629 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=69;, score=0.656 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=69;, score=0.651 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=71;, score=0.630 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=71;, score=0.645 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=71;, score=0.621 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=71;, score=0.651 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=71;, score=0.652 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=73;, score=0.623 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=73;, score=0.641 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=73;, score=0.616 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=73;, score=0.644 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=73;, score=0.640 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=75;, score=0.626 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=75;, score=0.642 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=75;, score=0.616 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=75;, score=0.646 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=75;, score=0.646 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=77;, score=0.623 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=77;, score=0.646 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=77;, score=0.613 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=77;, score=0.644 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=77;, score=0.645 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=79;, score=0.623 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=79;, score=0.640 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=79;, score=0.615 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=79;, score=0.642 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=79;, score=0.640 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=81;, score=0.631 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=81;, score=0.641 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=81;, score=0.618 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=81;, score=0.639 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=81;, score=0.649 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=83;, score=0.637 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=83;, score=0.639 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=83;, score=0.620 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=83;, score=0.646 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=83;, score=0.645 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=85;, score=0.623 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=85;, score=0.642 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=85;, score=0.613 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=85;, score=0.647 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=85;, score=0.644 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=87;, score=0.629 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=87;, score=0.641 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=87;, score=0.609 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=87;, score=0.640 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=87;, score=0.644 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=89;, score=0.636 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=89;, score=0.637 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=89;, score=0.608 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=89;, score=0.642 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=89;, score=0.641 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=91;, score=0.636 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=91;, score=0.647 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=91;, score=0.613 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=91;, score=0.639 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=91;, score=0.637 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=93;, score=0.635 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=93;, score=0.650 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=93;, score=0.615 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=93;, score=0.640 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=93;, score=0.641 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=95;, score=0.637 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=95;, score=0.655 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=95;, score=0.609 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=95;, score=0.636 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=95;, score=0.644 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=97;, score=0.634 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=97;, score=0.660 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=97;, score=0.609 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=97;, score=0.641 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=97;, score=0.651 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=99;, score=0.629 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=99;, score=0.652 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=99;, score=0.608 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=99;, score=0.644 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=99;, score=0.646 total time=   0.1s\n",
      "{'n_neighbors': 13}\n",
      "KNeighborsClassifier(n_neighbors=13)\n"
     ]
    }
   ],
   "source": [
    "parameters = dict(n_neighbors=[i for i in range(1,100) if i%2!= 0])\n",
    "\n",
    "# KNN model\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "# Find the best hyperparameters for each KNN model\n",
    "grid_knn = GridSearchCV(knn_model, parameters, refit = True, verbose = 3)\n",
    "grid_knn.fit(X_train, y_train)\n",
    "\n",
    "# print best parameter after tuning\n",
    "print(grid_knn.best_params_)\n",
    "\n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid_knn.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.53      0.61       501\n",
      "           1       0.62      0.78      0.69       499\n",
      "\n",
      "    accuracy                           0.65      1000\n",
      "   macro avg       0.66      0.65      0.65      1000\n",
      "weighted avg       0.66      0.65      0.65      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_predictions = grid_knn.predict(X_test)\n",
    "\n",
    "# print classification report\n",
    "print(classification_report(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8- using Random forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_features': max_features,\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'bootstrap': bootstrap\n",
    "}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "random_forest_model = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation,\n",
    "# search across 100 different combinations, and use all available cores\n",
    "grid_random_forest = RandomizedSearchCV(\n",
    "    estimator = random_forest_model,\n",
    "    param_distributions = random_grid,\n",
    "    n_iter = 100,\n",
    "    cv = 3,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs = -1)\n",
    "# Fit the random search model\n",
    "grid_random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.86       501\n",
      "           1       0.84      0.90      0.87       499\n",
      "\n",
      "    accuracy                           0.87      1000\n",
      "   macro avg       0.87      0.87      0.87      1000\n",
      "weighted avg       0.87      0.87      0.87      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_predictions = grid_random_forest.predict(X_test)\n",
    "\n",
    "# print classification report\n",
    "print(classification_report(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# result:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the accuracy in Naive byes model is 91% \n",
    "the accuracy inLogistic regression  model is 88% \n",
    "accuracy in SVM  model is 88% \n",
    "accuracy in KNN   model is 88% \n",
    "accuracy in Random Forest model is 88% "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
